{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rekhasahoo/ANEMIA/blob/main/ANEMIA_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLGmYM80R0Og",
        "outputId": "4bcdd938-b2dd-4dcb-d978-2668eb3f2c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Anemia Detection (Decision) ===\n",
            "\n",
            "--- KNN ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94      2034\n",
            "           1       0.92      0.86      0.89      1249\n",
            "\n",
            "    accuracy                           0.92      3283\n",
            "   macro avg       0.92      0.91      0.91      3283\n",
            "weighted avg       0.92      0.92      0.92      3283\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95      2034\n",
            "           1       0.93      0.89      0.91      1249\n",
            "\n",
            "    accuracy                           0.93      3283\n",
            "   macro avg       0.93      0.92      0.93      3283\n",
            "weighted avg       0.93      0.93      0.93      3283\n",
            "\n",
            "\n",
            "--- DecisionTree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      2034\n",
            "           1       0.89      0.89      0.89      1249\n",
            "\n",
            "    accuracy                           0.92      3283\n",
            "   macro avg       0.91      0.91      0.91      3283\n",
            "weighted avg       0.92      0.92      0.92      3283\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96      2034\n",
            "           1       0.98      0.87      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.95      0.94      0.94      3283\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:14:02] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XGBoost ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.96      2034\n",
            "           1       0.97      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "=== Anemia Type Prediction ===\n",
            "\n",
            "--- KNN ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.00      0.00      0.00        31\n",
            "           2       0.14      0.04      0.06       204\n",
            "           3       0.26      0.20      0.22       839\n",
            "           4       0.67      0.80      0.73      2169\n",
            "\n",
            "    accuracy                           0.58      3283\n",
            "   macro avg       0.21      0.21      0.20      3283\n",
            "weighted avg       0.52      0.58      0.54      3283\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.00      0.00      0.00        31\n",
            "           2       0.00      0.00      0.00       204\n",
            "           3       0.00      0.00      0.00       839\n",
            "           4       0.66      1.00      0.80      2169\n",
            "\n",
            "    accuracy                           0.66      3283\n",
            "   macro avg       0.13      0.20      0.16      3283\n",
            "weighted avg       0.44      0.66      0.53      3283\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- DecisionTree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.02      0.03      0.02        40\n",
            "           1       0.00      0.00      0.00        31\n",
            "           2       0.06      0.06      0.06       204\n",
            "           3       0.25      0.27      0.26       839\n",
            "           4       0.66      0.63      0.64      2169\n",
            "\n",
            "    accuracy                           0.49      3283\n",
            "   macro avg       0.20      0.20      0.20      3283\n",
            "weighted avg       0.50      0.49      0.50      3283\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.00      0.00      0.00        31\n",
            "           2       0.00      0.00      0.00       204\n",
            "           3       0.22      0.03      0.06       839\n",
            "           4       0.66      0.96      0.78      2169\n",
            "\n",
            "    accuracy                           0.64      3283\n",
            "   macro avg       0.18      0.20      0.17      3283\n",
            "weighted avg       0.49      0.64      0.53      3283\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:14:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XGBoost ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.00      0.00      0.00        31\n",
            "           2       0.00      0.00      0.00       204\n",
            "           3       0.27      0.06      0.09       839\n",
            "           4       0.66      0.94      0.78      2169\n",
            "\n",
            "    accuracy                           0.64      3283\n",
            "   macro avg       0.19      0.20      0.17      3283\n",
            "weighted avg       0.51      0.64      0.54      3283\n",
            "\n",
            "✅ Dataset with decision & anemia_type saved at /content/anemia_final_dataset_with_type.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Anemia Detection Pipeline with Type Detection from Turkey + Biochemical Rules\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load datasets\n",
        "# ---------------------------\n",
        "turkey = pd.read_csv(\"/content/TURKEY DATASET 1 (1).csv\")\n",
        "bangladesh = pd.read_csv(\"/content/BANGLADESH DATASET (1).csv\")\n",
        "lucknow2 = pd.read_csv(\"/content/Hepcidin Data Reformated 042320 (1).csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Standardize column names\n",
        "# ---------------------------\n",
        "def clean_cols(df):\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "    return df\n",
        "\n",
        "turkey = clean_cols(turkey)\n",
        "bangladesh = clean_cols(bangladesh)\n",
        "lucknow2 = clean_cols(lucknow2)\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Decision column\n",
        "# ---------------------------\n",
        "turkey['decision'] = turkey['all_class'].apply(lambda x: 0 if x == 0 else 1)\n",
        "bangladesh['decision'] = bangladesh['decision_class']\n",
        "lucknow2['decision'] = lucknow2['anemic']\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Select common columns + biochemical markers + decision\n",
        "# ---------------------------\n",
        "common_cols = ['rbc', 'hgb', 'mcv', 'mch', 'mchc', 'ferritin', 'b12', 'folate', 'decision', 'all_class']\n",
        "def select_cols(df, col_list):\n",
        "    cols_present = [c for c in col_list if c in df.columns]\n",
        "    return df[cols_present]\n",
        "\n",
        "turkey_sel = select_cols(turkey, common_cols)\n",
        "bangladesh_sel = select_cols(bangladesh, common_cols)\n",
        "lucknow2_sel = select_cols(lucknow2, common_cols)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Merge datasets\n",
        "# ---------------------------\n",
        "data = pd.concat([turkey_sel, bangladesh_sel, lucknow2_sel], ignore_index=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Convert numeric columns\n",
        "# ---------------------------\n",
        "numeric_cols = ['rbc', 'hgb', 'mcv', 'mch', 'mchc', 'ferritin', 'b12', 'folate']\n",
        "for col in numeric_cols:\n",
        "    if col in data.columns:\n",
        "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "# ---------------------------\n",
        "# 7. KNN Imputation for missing numeric values\n",
        "# ---------------------------\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "data[numeric_cols] = imputer.fit_transform(data[numeric_cols])\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Anemia type assignment\n",
        "# ---------------------------\n",
        "def assign_anemia_type(row):\n",
        "    # Turkey dataset: based on All_Class\n",
        "    if 'all_class' in row and not pd.isna(row['all_class']):\n",
        "        if row['all_class'] == 4: return 'B12_deficiency'\n",
        "        if row['all_class'] == 3: return 'Folate_deficiency'\n",
        "        if row['all_class'] == 2: return 'Iron_deficiency'\n",
        "        if row['all_class'] == 1: return 'HGB_deficiency'\n",
        "        return 'Normal'\n",
        "    # Other datasets: based on biochemical ranges\n",
        "    types = []\n",
        "    if 'ferritin' in row and row['ferritin'] < 20:\n",
        "        types.append('Iron_deficiency')\n",
        "    if 'b12' in row and row['b12'] < 200:\n",
        "        types.append('B12_deficiency')\n",
        "    if 'folate' in row and row['folate'] < 3:\n",
        "        types.append('Folate_deficiency')\n",
        "    return ','.join(types) if types else 'Normal'\n",
        "\n",
        "data['anemia_type'] = data.apply(assign_anemia_type, axis=1)\n",
        "\n",
        "# ---------------------------\n",
        "# 9. Encode target and type\n",
        "# ---------------------------\n",
        "le_target = LabelEncoder()\n",
        "data['decision'] = le_target.fit_transform(data['decision'])\n",
        "\n",
        "le_type = LabelEncoder()\n",
        "data['anemia_type_encoded'] = le_type.fit_transform(data['anemia_type'])\n",
        "\n",
        "# ---------------------------\n",
        "# 10. Split features & targets\n",
        "# ---------------------------\n",
        "X = data[numeric_cols]\n",
        "y_decision = data['decision']\n",
        "y_type = data['anemia_type_encoded']\n",
        "\n",
        "X_train, X_test, y_train_dec, y_test_dec = train_test_split(\n",
        "    X, y_decision, test_size=0.2, random_state=42, stratify=y_decision\n",
        ")\n",
        "_, _, y_train_type, y_test_type = train_test_split(\n",
        "    X, y_type, test_size=0.2, random_state=42, stratify=y_type\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 11. Scale features\n",
        "# ---------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# 12. ML Models for decision\n",
        "# ---------------------------\n",
        "ml_models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "print(\"=== Anemia Detection (Decision) ===\")\n",
        "for name, model in ml_models.items():\n",
        "    model.fit(X_train_scaled, y_train_dec)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(y_test_dec, y_pred))\n",
        "\n",
        "print(\"=== Anemia Type Prediction ===\")\n",
        "for name, model in ml_models.items():\n",
        "    model.fit(X_train_scaled, y_train_type)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(y_test_type, y_pred))\n",
        "\n",
        "# ---------------------------\n",
        "# 13. Save final dataset\n",
        "# ---------------------------\n",
        "data.to_csv(\"/content/anemia_final_dataset_with_type.csv\", index=False)\n",
        "print(\"✅ Dataset with decision & anemia_type saved at /content/anemia_final_dataset_with_type.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load cleaned dataset\n",
        "# ---------------------------\n",
        "data = pd.read_csv(\"/content/anemia_final_dataset_with_type.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Define target columns\n",
        "# ---------------------------\n",
        "X = data.drop(columns=['decision', 'anemia_type'], errors='ignore')\n",
        "y_dec = data['decision']\n",
        "\n",
        "# Encode anemia_type (string → numeric)\n",
        "le_type = LabelEncoder()\n",
        "y_type = le_type.fit_transform(data['anemia_type'].astype(str))\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Impute missing values\n",
        "# ---------------------------\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
        "cat_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "X[numeric_features] = imputer_num.fit_transform(X[numeric_features])\n",
        "\n",
        "if len(cat_features) > 0:\n",
        "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "    X[cat_features] = imputer_cat.fit_transform(X[cat_features])\n",
        "\n",
        "# Encode categorical columns if any\n",
        "for col in cat_features:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Train/test split\n",
        "# ---------------------------\n",
        "X_train, X_test, y_train_dec, y_test_dec, y_train_type, y_test_type = train_test_split(\n",
        "    X, y_dec, y_type, test_size=0.2, random_state=42, stratify=y_dec\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Scale features\n",
        "# ---------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Train decision models\n",
        "# ---------------------------\n",
        "ml_models = {\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "}\n",
        "\n",
        "print(\"=== Anemia Decision Prediction ===\")\n",
        "for name, model in ml_models.items():\n",
        "    model.fit(X_train_scaled, y_train_dec)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(y_test_dec, y_pred))\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Type prediction for anemic patients only\n",
        "# ---------------------------\n",
        "mask_train_anemic = y_train_dec == 1\n",
        "mask_test_anemic = y_test_dec == 1\n",
        "\n",
        "X_train_anemic = X_train_scaled[mask_train_anemic.values]\n",
        "X_test_anemic = X_test_scaled[mask_test_anemic.values]\n",
        "\n",
        "y_train_type_anemic = y_train_type[mask_train_anemic.values]\n",
        "y_test_type_anemic = y_test_type[mask_test_anemic.values]\n",
        "\n",
        "print(\"\\n=== Anemia Type Prediction (Only Anemic Patients) ===\")\n",
        "for name, model in ml_models.items():\n",
        "    model.fit(X_train_anemic, y_train_type_anemic)\n",
        "    y_pred_type = model.predict(X_test_anemic)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(\n",
        "        y_test_type_anemic,\n",
        "        y_pred_type,\n",
        "        target_names=le_type.classes_\n",
        "    ))\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Save final dataset\n",
        "# ---------------------------\n",
        "data.to_csv(\"/content/anemia_final_dataset_ready_for_ml.csv\", index=False)\n",
        "print(\"✅ Dataset saved at /content/anemia_final_dataset_ready_for_ml.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7ln6N0sR3mn",
        "outputId": "442cc8e2-e063-417b-825e-1c7de212337e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Anemia Decision Prediction ===\n",
            "\n",
            "--- KNN ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      2034\n",
            "           1       0.99      0.97      0.98      1249\n",
            "\n",
            "    accuracy                           0.99      3283\n",
            "   macro avg       0.99      0.98      0.99      3283\n",
            "weighted avg       0.99      0.99      0.99      3283\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      2034\n",
            "           1       1.00      0.98      0.99      1249\n",
            "\n",
            "    accuracy                           0.99      3283\n",
            "   macro avg       0.99      0.99      0.99      3283\n",
            "weighted avg       0.99      0.99      0.99      3283\n",
            "\n",
            "\n",
            "--- DecisionTree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      2034\n",
            "           1       0.99      0.98      0.98      1249\n",
            "\n",
            "    accuracy                           0.99      3283\n",
            "   macro avg       0.99      0.99      0.99      3283\n",
            "weighted avg       0.99      0.99      0.99      3283\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      2034\n",
            "           1       0.99      0.98      0.99      1249\n",
            "\n",
            "    accuracy                           0.99      3283\n",
            "   macro avg       0.99      0.99      0.99      3283\n",
            "weighted avg       0.99      0.99      0.99      3283\n",
            "\n",
            "\n",
            "--- XGBoost ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      2034\n",
            "           1       0.99      0.98      0.99      1249\n",
            "\n",
            "    accuracy                           0.99      3283\n",
            "   macro avg       0.99      0.99      0.99      3283\n",
            "weighted avg       0.99      0.99      0.99      3283\n",
            "\n",
            "\n",
            "=== Anemia Type Prediction (Only Anemic Patients) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:20:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- KNN ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       1.00      1.00      1.00        30\n",
            "Folate_deficiency       1.00      1.00      1.00        26\n",
            "   HGB_deficiency       1.00      0.98      0.99       195\n",
            "  Iron_deficiency       1.00      1.00      1.00       837\n",
            "           Normal       0.99      1.00      1.00       161\n",
            "\n",
            "         accuracy                           1.00      1249\n",
            "        macro avg       1.00      1.00      1.00      1249\n",
            "     weighted avg       1.00      1.00      1.00      1249\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       1.00      1.00      1.00        30\n",
            "Folate_deficiency       1.00      1.00      1.00        26\n",
            "   HGB_deficiency       1.00      1.00      1.00       195\n",
            "  Iron_deficiency       1.00      1.00      1.00       837\n",
            "           Normal       1.00      0.99      1.00       161\n",
            "\n",
            "         accuracy                           1.00      1249\n",
            "        macro avg       1.00      1.00      1.00      1249\n",
            "     weighted avg       1.00      1.00      1.00      1249\n",
            "\n",
            "\n",
            "--- DecisionTree ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       1.00      1.00      1.00        30\n",
            "Folate_deficiency       1.00      1.00      1.00        26\n",
            "   HGB_deficiency       1.00      1.00      1.00       195\n",
            "  Iron_deficiency       1.00      1.00      1.00       837\n",
            "           Normal       1.00      1.00      1.00       161\n",
            "\n",
            "         accuracy                           1.00      1249\n",
            "        macro avg       1.00      1.00      1.00      1249\n",
            "     weighted avg       1.00      1.00      1.00      1249\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       1.00      1.00      1.00        30\n",
            "Folate_deficiency       1.00      1.00      1.00        26\n",
            "   HGB_deficiency       1.00      1.00      1.00       195\n",
            "  Iron_deficiency       1.00      1.00      1.00       837\n",
            "           Normal       1.00      1.00      1.00       161\n",
            "\n",
            "         accuracy                           1.00      1249\n",
            "        macro avg       1.00      1.00      1.00      1249\n",
            "     weighted avg       1.00      1.00      1.00      1249\n",
            "\n",
            "\n",
            "--- XGBoost ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       1.00      1.00      1.00        30\n",
            "Folate_deficiency       1.00      1.00      1.00        26\n",
            "   HGB_deficiency       1.00      1.00      1.00       195\n",
            "  Iron_deficiency       1.00      1.00      1.00       837\n",
            "           Normal       1.00      1.00      1.00       161\n",
            "\n",
            "         accuracy                           1.00      1249\n",
            "        macro avg       1.00      1.00      1.00      1249\n",
            "     weighted avg       1.00      1.00      1.00      1249\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:20:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset saved at /content/anemia_final_dataset_ready_for_ml.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "excluding biomarkers\n"
      ],
      "metadata": {
        "id": "-65j3ofpSGvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# =======================\n",
        "# Load dataset\n",
        "# =======================\n",
        "df = pd.read_csv(\"/content/anemia_final_dataset_ready_for_ml.csv\")\n",
        "\n",
        "# =======================\n",
        "# Features and targets\n",
        "# =======================\n",
        "# Drop non-feature columns\n",
        "X = df.drop(columns=['decision', 'anemia_type', 'anemia_type_encoded', 'all_class'], errors='ignore')\n",
        "\n",
        "# Target 1: Binary decision (0 = not anemic, 1 = anemic)\n",
        "y_dec = df['decision']\n",
        "\n",
        "# Target 2: Anemia type (only for anemic patients)\n",
        "y_type = df['anemia_type_encoded']\n",
        "df_type = df[df['decision'] == 1]   # filter only anemic\n",
        "X_type = df_type.drop(columns=['decision', 'anemia_type', 'anemia_type_encoded', 'all_class'], errors='ignore')\n",
        "y_type = df_type['anemia_type_encoded']\n",
        "\n",
        "# Scale features (important for SVM/KNN)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_type_scaled = scaler.fit_transform(X_type)\n",
        "\n",
        "# =======================\n",
        "# Models\n",
        "# =======================\n",
        "models = {\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"SVM\": SVC(kernel='rbf', probability=True),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# =======================\n",
        "# 1. Binary Anemia Decision\n",
        "# =======================\n",
        "print(\"=== Anemia Decision Prediction (CV) ===\\n\")\n",
        "for name, model in models.items():\n",
        "    y_pred = cross_val_predict(model, X_scaled, y_dec, cv=cv)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(classification_report(y_dec, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# =======================\n",
        "# 2. Anemia Type Prediction (only anemic patients)\n",
        "# =======================\n",
        "print(\"\\n=== Anemia Type Prediction (CV, only anemic patients) ===\\n\")\n",
        "for name, model in models.items():\n",
        "    y_pred_type = cross_val_predict(model, X_type_scaled, y_type, cv=cv)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(classification_report(y_type, y_pred_type, target_names=df['anemia_type'].unique()))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF3Ifg3qSJw3",
        "outputId": "5163eeef-6f95-4a1b-8863-3b0ef3443159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Anemia Decision Prediction (CV) ===\n",
            "\n",
            "--- KNN ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94     10170\n",
            "           1       0.92      0.87      0.89      6244\n",
            "\n",
            "    accuracy                           0.92     16414\n",
            "   macro avg       0.92      0.91      0.91     16414\n",
            "weighted avg       0.92      0.92      0.92     16414\n",
            "\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95     10170\n",
            "           1       0.94      0.89      0.92      6244\n",
            "\n",
            "    accuracy                           0.94     16414\n",
            "   macro avg       0.94      0.93      0.93     16414\n",
            "weighted avg       0.94      0.94      0.94     16414\n",
            "\n",
            "\n",
            "\n",
            "--- DecisionTree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94     10170\n",
            "           1       0.90      0.90      0.90      6244\n",
            "\n",
            "    accuracy                           0.92     16414\n",
            "   macro avg       0.92      0.92      0.92     16414\n",
            "weighted avg       0.92      0.92      0.92     16414\n",
            "\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96     10170\n",
            "           1       0.98      0.89      0.93      6244\n",
            "\n",
            "    accuracy                           0.95     16414\n",
            "   macro avg       0.96      0.94      0.95     16414\n",
            "weighted avg       0.95      0.95      0.95     16414\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:21:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- XGBoost ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96     10170\n",
            "           1       0.96      0.89      0.92      6244\n",
            "\n",
            "    accuracy                           0.94     16414\n",
            "   macro avg       0.95      0.93      0.94     16414\n",
            "weighted avg       0.95      0.94      0.94     16414\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "=== Anemia Type Prediction (CV, only anemic patients) ===\n",
            "\n",
            "--- KNN ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.37      0.20      0.26       201\n",
            "Folate_deficiency       0.47      0.26      0.34       153\n",
            "  Iron_deficiency       0.42      0.33      0.37      1019\n",
            "   HGB_deficiency       0.80      0.88      0.84      4189\n",
            "           Normal       0.87      0.77      0.82       682\n",
            "\n",
            "         accuracy                           0.74      6244\n",
            "        macro avg       0.58      0.49      0.52      6244\n",
            "     weighted avg       0.72      0.74      0.73      6244\n",
            "\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.87      0.10      0.18       201\n",
            "Folate_deficiency       0.59      0.08      0.15       153\n",
            "  Iron_deficiency       0.61      0.12      0.21      1019\n",
            "   HGB_deficiency       0.76      0.98      0.85      4189\n",
            "           Normal       0.91      0.79      0.85       682\n",
            "\n",
            "         accuracy                           0.77      6244\n",
            "        macro avg       0.75      0.42      0.45      6244\n",
            "     weighted avg       0.75      0.77      0.71      6244\n",
            "\n",
            "\n",
            "\n",
            "--- DecisionTree ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.41      0.47      0.44       201\n",
            "Folate_deficiency       0.49      0.52      0.51       153\n",
            "  Iron_deficiency       0.37      0.38      0.38      1019\n",
            "   HGB_deficiency       0.79      0.78      0.78      4189\n",
            "           Normal       0.73      0.76      0.74       682\n",
            "\n",
            "         accuracy                           0.69      6244\n",
            "        macro avg       0.56      0.58      0.57      6244\n",
            "     weighted avg       0.70      0.69      0.70      6244\n",
            "\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.61      0.38      0.47       201\n",
            "Folate_deficiency       0.62      0.39      0.48       153\n",
            "  Iron_deficiency       0.56      0.32      0.41      1019\n",
            "   HGB_deficiency       0.80      0.91      0.85      4189\n",
            "           Normal       0.86      0.81      0.83       682\n",
            "\n",
            "         accuracy                           0.78      6244\n",
            "        macro avg       0.69      0.56      0.61      6244\n",
            "     weighted avg       0.76      0.78      0.76      6244\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:22:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:22:21] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [17:22:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- XGBoost ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.55      0.42      0.48       201\n",
            "Folate_deficiency       0.59      0.51      0.55       153\n",
            "  Iron_deficiency       0.53      0.35      0.42      1019\n",
            "   HGB_deficiency       0.80      0.89      0.84      4189\n",
            "           Normal       0.88      0.82      0.85       682\n",
            "\n",
            "         accuracy                           0.77      6244\n",
            "        macro avg       0.67      0.60      0.63      6244\n",
            "     weighted avg       0.75      0.77      0.76      6244\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "applying smote"
      ],
      "metadata": {
        "id": "aNdgAa7qSWTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load dataset\n",
        "# ---------------------------\n",
        "df = pd.read_csv(\"/content/anemia_final_dataset_ready_for_ml.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Define features and targets\n",
        "# ---------------------------\n",
        "X = df[['rbc','hgb','mcv','mch','mchc','b12','folate','ferritin']]\n",
        "y_dec = df['decision']              # 0: Not Anemic, 1: Anemic\n",
        "y_type = df['anemia_type_encoded']  # Encoded type\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Impute missing values\n",
        "# ---------------------------\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Scale features\n",
        "# ---------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Define ML models\n",
        "# ---------------------------\n",
        "ml_models = {\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    \"XGBoost\": xgb.XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
        "}\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Anemia Decision Prediction with CV\n",
        "# ---------------------------\n",
        "print(\"=== Anemia Decision Prediction (CV) ===\")\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for name, model in ml_models.items():\n",
        "    y_pred_cv = cross_val_predict(model, X_scaled, y_dec, cv=skf)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(y_dec, y_pred_cv))\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Anemia Type Prediction (only anemic patients)\n",
        "# ---------------------------\n",
        "mask_anemic = y_dec == 1\n",
        "X_anemic = X_scaled[mask_anemic]\n",
        "y_type_anemic = y_type[mask_anemic]\n",
        "\n",
        "# Mapping encoded labels to type names for readability\n",
        "type_mapping = dict(zip(df['anemia_type_encoded'], df['anemia_type']))\n",
        "type_names = [type_mapping[i] for i in sorted(type_mapping.keys())]\n",
        "\n",
        "print(\"\\n=== Anemia Type Prediction (CV, only anemic patients) ===\")\n",
        "for name, model in ml_models.items():\n",
        "    y_pred_type_cv = cross_val_predict(model, X_anemic, y_type_anemic, cv=skf)\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(classification_report(y_type_anemic, y_pred_type_cv, target_names=type_names))\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Save final dataset\n",
        "# ---------------------------\n",
        "df.to_csv(\"/content/anemia_final_dataset_ready_for_ml.csv\", index=False)\n",
        "print(\"✅ Dataset saved at /content/anemia_final_dataset_ready_for_ml.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEXYGmHMSYDn",
        "outputId": "113aa152-fe7c-417c-9c46-87c077540727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Anemia Decision Prediction (CV) ===\n",
            "\n",
            "--- KNN ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94     10170\n",
            "           1       0.92      0.87      0.89      6244\n",
            "\n",
            "    accuracy                           0.92     16414\n",
            "   macro avg       0.92      0.91      0.91     16414\n",
            "weighted avg       0.92      0.92      0.92     16414\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95     10170\n",
            "           1       0.94      0.89      0.92      6244\n",
            "\n",
            "    accuracy                           0.94     16414\n",
            "   macro avg       0.94      0.93      0.93     16414\n",
            "weighted avg       0.94      0.94      0.94     16414\n",
            "\n",
            "\n",
            "--- DecisionTree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94     10170\n",
            "           1       0.90      0.90      0.90      6244\n",
            "\n",
            "    accuracy                           0.92     16414\n",
            "   macro avg       0.92      0.92      0.92     16414\n",
            "weighted avg       0.92      0.92      0.92     16414\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96     10170\n",
            "           1       0.98      0.89      0.93      6244\n",
            "\n",
            "    accuracy                           0.95     16414\n",
            "   macro avg       0.96      0.94      0.95     16414\n",
            "weighted avg       0.95      0.95      0.95     16414\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:35:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:35:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XGBoost ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96     10170\n",
            "           1       0.96      0.89      0.92      6244\n",
            "\n",
            "    accuracy                           0.94     16414\n",
            "   macro avg       0.95      0.93      0.94     16414\n",
            "weighted avg       0.95      0.94      0.94     16414\n",
            "\n",
            "\n",
            "=== Anemia Type Prediction (CV, only anemic patients) ===\n",
            "\n",
            "--- KNN ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.31      0.17      0.22       201\n",
            "Folate_deficiency       0.45      0.27      0.33       153\n",
            "   HGB_deficiency       0.39      0.31      0.34      1019\n",
            "  Iron_deficiency       0.79      0.88      0.83      4189\n",
            "           Normal       0.86      0.77      0.82       682\n",
            "\n",
            "         accuracy                           0.73      6244\n",
            "        macro avg       0.56      0.48      0.51      6244\n",
            "     weighted avg       0.71      0.73      0.72      6244\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.90      0.09      0.16       201\n",
            "Folate_deficiency       0.62      0.08      0.15       153\n",
            "   HGB_deficiency       0.60      0.13      0.21      1019\n",
            "  Iron_deficiency       0.76      0.98      0.85      4189\n",
            "           Normal       0.91      0.79      0.84       682\n",
            "\n",
            "         accuracy                           0.77      6244\n",
            "        macro avg       0.76      0.41      0.44      6244\n",
            "     weighted avg       0.75      0.77      0.71      6244\n",
            "\n",
            "\n",
            "--- DecisionTree ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.41      0.47      0.44       201\n",
            "Folate_deficiency       0.49      0.52      0.51       153\n",
            "   HGB_deficiency       0.37      0.38      0.38      1019\n",
            "  Iron_deficiency       0.79      0.78      0.78      4189\n",
            "           Normal       0.73      0.76      0.74       682\n",
            "\n",
            "         accuracy                           0.69      6244\n",
            "        macro avg       0.56      0.58      0.57      6244\n",
            "     weighted avg       0.70      0.69      0.70      6244\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.65      0.41      0.50       201\n",
            "Folate_deficiency       0.64      0.40      0.49       153\n",
            "   HGB_deficiency       0.55      0.32      0.40      1019\n",
            "  Iron_deficiency       0.80      0.91      0.85      4189\n",
            "           Normal       0.86      0.81      0.83       682\n",
            "\n",
            "         accuracy                           0.77      6244\n",
            "        macro avg       0.70      0.57      0.61      6244\n",
            "     weighted avg       0.75      0.77      0.76      6244\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:36:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:36:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:36:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:36:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XGBoost ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.55      0.42      0.48       201\n",
            "Folate_deficiency       0.59      0.51      0.55       153\n",
            "   HGB_deficiency       0.53      0.35      0.42      1019\n",
            "  Iron_deficiency       0.80      0.89      0.84      4189\n",
            "           Normal       0.88      0.82      0.85       682\n",
            "\n",
            "         accuracy                           0.77      6244\n",
            "        macro avg       0.67      0.60      0.63      6244\n",
            "     weighted avg       0.75      0.77      0.76      6244\n",
            "\n",
            "✅ Dataset saved at /content/anemia_final_dataset_ready_for_ml.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load dataset\n",
        "# ---------------------------\n",
        "df = pd.read_csv(\"/content/anemia_final_dataset_ready_for_ml.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Define features and targets\n",
        "# ---------------------------\n",
        "X = df[['rbc','hgb','mcv','mch','mchc','b12','folate','ferritin']]\n",
        "y_dec = df['decision']              # 0: Not Anemic, 1: Anemic\n",
        "y_type = df['anemia_type_encoded']  # Encoded type\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Impute missing values\n",
        "# ---------------------------\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Scale features\n",
        "# ---------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Base learners for stacking\n",
        "# ---------------------------\n",
        "base_learners = [\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('rf', RandomForestClassifier(random_state=42, n_estimators=100)),\n",
        "    ('svm', SVC(probability=True, random_state=42))\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Meta-learner\n",
        "# ---------------------------\n",
        "meta_learner = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Stacking classifier for Anemia Decision (0/1)\n",
        "# ---------------------------\n",
        "stack_model_dec = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=5,\n",
        "    stack_method='predict_proba',  # better for meta-learner learning probabilities\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Cross-validation predictions\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "y_pred_dec = cross_val_predict(stack_model_dec, X_scaled, y_dec, cv=skf)\n",
        "\n",
        "print(\"=== Anemia Decision Prediction (Stacking Ensemble CV) ===\")\n",
        "print(classification_report(y_dec, y_pred_dec))\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Stacking classifier for Anemia Type (only anemic patients)\n",
        "# ---------------------------\n",
        "mask_anemic = y_dec == 1\n",
        "X_anemic = X_scaled[mask_anemic]\n",
        "y_type_anemic = y_type[mask_anemic]\n",
        "\n",
        "stack_model_type = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=meta_learner,\n",
        "    cv=5,\n",
        "    stack_method='predict_proba',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "y_pred_type = cross_val_predict(stack_model_type, X_anemic, y_type_anemic, cv=skf)\n",
        "\n",
        "# Map encoded type to readable names\n",
        "type_mapping = dict(zip(df['anemia_type_encoded'], df['anemia_type']))\n",
        "type_names = [type_mapping[i] for i in sorted(type_mapping.keys())]\n",
        "\n",
        "print(\"\\n=== Anemia Type Prediction (Stacking Ensemble CV, Only Anemic Patients) ===\")\n",
        "print(classification_report(y_type_anemic, y_pred_type, target_names=type_names))\n",
        "\n",
        "# ---------------------------\n",
        "# 9. Save dataset for reference\n",
        "# ---------------------------\n",
        "df.to_csv(\"/content/anemia_final_dataset_ready_for_ml.csv\", index=False)\n",
        "print(\"✅ Dataset saved at /content/anemia_final_dataset_ready_for_ml.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF8LgNxBTfMX",
        "outputId": "4bc5d8d4-1e6d-456a-97fb-62e0ce5a358d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Anemia Decision Prediction (Stacking Ensemble CV) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96     10170\n",
            "           1       0.97      0.89      0.93      6244\n",
            "\n",
            "    accuracy                           0.95     16414\n",
            "   macro avg       0.95      0.94      0.94     16414\n",
            "weighted avg       0.95      0.95      0.95     16414\n",
            "\n",
            "\n",
            "=== Anemia Type Prediction (Stacking Ensemble CV, Only Anemic Patients) ===\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   B12_deficiency       0.60      0.36      0.45       201\n",
            "Folate_deficiency       0.69      0.39      0.50       153\n",
            "   HGB_deficiency       0.60      0.22      0.32      1019\n",
            "  Iron_deficiency       0.78      0.94      0.85      4189\n",
            "           Normal       0.90      0.80      0.85       682\n",
            "\n",
            "         accuracy                           0.78      6244\n",
            "        macro avg       0.71      0.54      0.59      6244\n",
            "     weighted avg       0.76      0.78      0.74      6244\n",
            "\n",
            "✅ Dataset saved at /content/anemia_final_dataset_ready_for_ml.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMOTE + Undersampling → balances both small and large classes.\n",
        "\n",
        "Class weights → forces the model to care more about rare deficiencies.\n",
        "\n",
        "Stacking ensemble"
      ],
      "metadata": {
        "id": "50gzcxHQYGEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# IMPORTS\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_csv('/content/anemia_final_dataset_ready_for_ml.csv')\n",
        "\n",
        "# FEATURES\n",
        "features = ['rbc','hgb','mcv','mch','mchc','b12','folate','ferritin']\n",
        "\n",
        "# TARGETS\n",
        "target_decision = 'decision'\n",
        "target_type = 'anemia_type_encoded'\n",
        "\n",
        "# -----------------------------\n",
        "# SPLIT DATA (train/test)\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train_dec, y_test_dec = train_test_split(\n",
        "    df[features], df[target_decision], test_size=0.2, random_state=42, stratify=df[target_decision]\n",
        ")\n",
        "\n",
        "X_train_type, X_test_type, y_train_type, y_test_type = train_test_split(\n",
        "    df[features], df[target_type], test_size=0.2, random_state=42, stratify=df[target_type]\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# BALANCING (SMOTE + Undersampling)\n",
        "# -----------------------------\n",
        "over = SMOTE(random_state=42)\n",
        "under = RandomUnderSampler(random_state=42)\n",
        "\n",
        "# Decision target (binary)\n",
        "X_train_dec_bal, y_train_dec_bal = Pipeline([\n",
        "    ('over', over),\n",
        "    ('under', under)\n",
        "]).fit_resample(X_train, y_train_dec)\n",
        "\n",
        "# Type target (multiclass)\n",
        "X_train_type_bal, y_train_type_bal = Pipeline([\n",
        "    ('over', over),\n",
        "    ('under', under)\n",
        "]).fit_resample(X_train_type, y_train_type)\n",
        "\n",
        "# -----------------------------\n",
        "# FEATURE SCALING\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_dec_scaled = scaler.fit_transform(X_train_dec_bal)\n",
        "X_test_dec_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_type_scaled = scaler.fit_transform(X_train_type_bal)\n",
        "X_test_type_scaled = scaler.transform(X_test_type)\n",
        "\n",
        "# -----------------------------\n",
        "# STACKING ENSEMBLE with CLASS WEIGHTS\n",
        "# -----------------------------\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)),\n",
        "    ('dt', DecisionTreeClassifier(class_weight='balanced', random_state=42)),\n",
        "    ('knn', KNeighborsClassifier()),  # no class_weight here\n",
        "    ('svc', SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=42))\n",
        "]\n",
        "\n",
        "# --- Anemia Decision (Binary)\n",
        "stack_clf_dec = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "    cv=5\n",
        ")\n",
        "stack_clf_dec.fit(X_train_dec_scaled, y_train_dec_bal)\n",
        "y_pred_dec = stack_clf_dec.predict(X_test_dec_scaled)\n",
        "print(\"=== Anemia Decision Prediction (Stacking Ensemble, Balanced) ===\")\n",
        "print(classification_report(y_test_dec, y_pred_dec))\n",
        "\n",
        "# --- Anemia Type (Multiclass)\n",
        "stack_clf_type = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=LogisticRegression(class_weight='balanced', max_iter=1000),\n",
        "    cv=5\n",
        ")\n",
        "stack_clf_type.fit(X_train_type_scaled, y_train_type_bal)\n",
        "y_pred_type = stack_clf_type.predict(X_test_type_scaled)\n",
        "print(\"=== Anemia Type Prediction (Stacking Ensemble, Balanced) ===\")\n",
        "print(classification_report(y_test_type, y_pred_type))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHmzZev2YJwU",
        "outputId": "dcb132e7-9310-4547-96eb-d7d3418252c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Anemia Decision Prediction (Stacking Ensemble, Balanced) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95      2034\n",
            "           1       0.94      0.89      0.91      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.94      0.93      0.93      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "=== Anemia Type Prediction (Stacking Ensemble, Balanced) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.42      0.35        40\n",
            "           1       0.44      0.39      0.41        31\n",
            "           2       0.34      0.46      0.39       204\n",
            "           3       0.80      0.74      0.77       839\n",
            "           4       0.95      0.94      0.94      2169\n",
            "\n",
            "    accuracy                           0.85      3283\n",
            "   macro avg       0.57      0.59      0.57      3283\n",
            "weighted avg       0.86      0.85      0.85      3283\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# IMPORTS\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Import New Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    VotingClassifier, # <-- New Ensemble\n",
        "    StackingClassifier\n",
        ")\n",
        "# You may need to install these: pip install xgboost lightgbm\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    from lightgbm import LGBMClassifier\n",
        "    HAVE_BOOSTING = True\n",
        "except ImportError:\n",
        "    HAVE_BOOSTING = False\n",
        "    print(\"XGBoost/LightGBM not installed. Skipping those models.\")\n",
        "    print(\"To install: pip install xgboost lightgbm\")\n",
        "\n",
        "# Import Imbalanced-Learn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "try:\n",
        "    df = pd.read_csv('/content/anemia_final_dataset_ready_for_ml.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset file not found.\")\n",
        "    print(\"Please ensure '/content/anemia_final_dataset_ready_for_ml.csv' is uploaded.\")\n",
        "    exit()\n",
        "\n",
        "# FEATURES\n",
        "features = ['rbc', 'hgb', 'mcv', 'mch', 'mchc', 'b12', 'folate', 'ferritin']\n",
        "# TARGETS\n",
        "target_decision = 'decision'\n",
        "target_type = 'anemia_type_encoded'\n",
        "\n",
        "# -----------------------------\n",
        "# 1. SIMPLIFIED DATA SPLIT\n",
        "# -----------------------------\n",
        "# We only need one X split, as the features are the same for both tasks.\n",
        "X = df[features]\n",
        "y_dec = df[target_decision]\n",
        "y_type = df[target_type]\n",
        "\n",
        "# Split for Anemia Decision (Binary)\n",
        "X_train, X_test, y_train_dec, y_test_dec = train_test_split(\n",
        "    X, y_dec, test_size=0.2, random_state=42, stratify=y_dec\n",
        ")\n",
        "\n",
        "# Split for Anemia Type (Multiclass)\n",
        "# We use the *same* X_train/X_test from the split above for consistency.\n",
        "# We just need to get the corresponding y_type labels for those splits.\n",
        "y_train_type = y_type.loc[X_train.index]\n",
        "y_test_type = y_type.loc[X_test.index]\n",
        "\n",
        "print(f\"Original X_train shape: {X_train.shape}\")\n",
        "print(f\"Original X_test shape: {X_test.shape}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. FEATURE SCALING (THE CORRECT WAY)\n",
        "# -----------------------------\n",
        "# Fit the scaler ONLY on the original training data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "# Transform the test data using the scaler fit on the training data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. BALANCING (Applied AFTER scaling)\n",
        "# -----------------------------\n",
        "# Define the resampling strategy\n",
        "over = SMOTE(random_state=42, k_neighbors=3) # k_neighbors=3 (or less) may be needed if a class is very small\n",
        "under = RandomUnderSampler(random_state=42)\n",
        "balancing_pipeline = ImbPipeline([('over', over), ('under', under)])\n",
        "\n",
        "# Apply balancing only to the (scaled) training sets\n",
        "print(\"Balancing binary 'decision' target...\")\n",
        "X_train_dec_bal, y_train_dec_bal = balancing_pipeline.fit_resample(X_train_scaled, y_train_dec)\n",
        "\n",
        "print(\"Balancing multiclass 'type' target...\")\n",
        "X_train_type_bal, y_train_type_bal = balancing_pipeline.fit_resample(X_train_scaled, y_train_type)\n",
        "\n",
        "print(f\"Balanced X_train (decision): {X_train_dec_bal.shape}\")\n",
        "print(f\"Balanced X_train (type): {X_train_type_bal.shape}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4. SECTION 1: INDIVIDUAL MODELS\n",
        "# -----------------------------\n",
        "# We are resampling, so we don't need 'class_weight'\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
        "    \"Support Vector (RBF)\": SVC(kernel='rbf', random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "if HAVE_BOOSTING:\n",
        "    models[\"XGBoost\"] = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
        "    models[\"LightGBM\"] = LGBMClassifier(random_state=42, verbose=-1)\n",
        "\n",
        "# --- Train & Evaluate on Anemia Decision (Binary) ---\n",
        "print(\"=\" * 30)\n",
        "print(\"  INDIVIDUAL MODELS: ANEMIA DECISION (BINARY)  \")\n",
        "print(\"=\" * 30)\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "    model.fit(X_train_dec_bal, y_train_dec_bal)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(classification_report(y_test_dec, y_pred))\n",
        "\n",
        "# --- Train & Evaluate on Anemia Type (Multiclass) ---\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  INDIVIDUAL MODELS: ANEMIA TYPE (MULTICLASS)  \")\n",
        "print(\"=\" * 30)\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "    model.fit(X_train_type_bal, y_train_type_bal)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(classification_report(y_test_type, y_pred, zero_division=0))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5. SECTION 2: ENSEMBLE LEARNING (VOTING)\n",
        "# -----------------------------\n",
        "# A Voting ensemble is simpler than Stacking. It just averages predictions.\n",
        "# We'll use a few good, but different, models.\n",
        "estimators_voting = [\n",
        "    ('rf', RandomForestClassifier(random_state=42)),\n",
        "    ('svc', SVC(kernel='rbf', probability=True, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(random_state=42))\n",
        "]\n",
        "\n",
        "# --- Voting: Anemia Decision (Binary) ---\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  VOTING ENSEMBLE: ANEMIA DECISION (BINARY)  \")\n",
        "print(\"=\" * 30)\n",
        "voting_clf_dec = VotingClassifier(estimators=estimators_voting, voting='soft')\n",
        "voting_clf_dec.fit(X_train_dec_bal, y_train_dec_bal)\n",
        "y_pred_voting_dec = voting_clf_dec.predict(X_test_scaled)\n",
        "print(classification_report(y_test_dec, y_pred_voting_dec))\n",
        "\n",
        "# --- Voting: Anemia Type (Multiclass) ---\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  VOTING ENSEMBLE: ANEMIA TYPE (MULTICLASS)  \")\n",
        "print(\"=\" * 30)\n",
        "voting_clf_type = VotingClassifier(estimators=estimators_voting, voting='soft')\n",
        "voting_clf_type.fit(X_train_type_bal, y_train_type_bal)\n",
        "y_pred_voting_type = voting_clf_type.predict(X_test_scaled)\n",
        "print(classification_report(y_test_type, y_pred_voting_type, zero_division=0))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 6. SECTION 3: ENSEMBLE LEARNING (STACKING)\n",
        "# -----------------------------\n",
        "# This is your original code, now using the correctly scaled/balanced data.\n",
        "# Note: I removed 'class_weight' as we are already balancing with SMOTE/RUS.\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
        "]\n",
        "\n",
        "# --- Stacking: Anemia Decision (Binary) ---\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  STACKING ENSEMBLE: ANEMIA DECISION (BINARY)  \")\n",
        "print(\"=\" * 30)\n",
        "stack_clf_dec = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5\n",
        ")\n",
        "stack_clf_dec.fit(X_train_dec_bal, y_train_dec_bal)\n",
        "y_pred_dec = stack_clf_dec.predict(X_test_scaled)\n",
        "print(classification_report(y_test_dec, y_pred_dec))\n",
        "\n",
        "# --- Stacking: Anemia Type (Multiclass) ---\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  STACKING ENSEMBLE: ANEMIA TYPE (MULTICLASS)  \")\n",
        "print(\"=\" * 30)\n",
        "stack_clf_type = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5\n",
        ")\n",
        "stack_clf_type.fit(X_train_type_bal, y_train_type_bal)\n",
        "y_pred_type = stack_clf_type.predict(X_test_scaled)\n",
        "print(classification_report(y_test_type, y_pred_type, zero_division=0))\n",
        "\n",
        "print(\"\\n=== Model Training Complete ===\")\n"
      ],
      "metadata": {
        "id": "jICPnIGwBuly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a94da43-c739-4201-a00f-c42160bdd47e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_train shape: (13131, 8)\n",
            "Original X_test shape: (3283, 8)\n",
            "------------------------------\n",
            "Balancing binary 'decision' target...\n",
            "Balancing multiclass 'type' target...\n",
            "Balanced X_train (decision): (16272, 8)\n",
            "Balanced X_train (type): (43250, 8)\n",
            "------------------------------\n",
            "==============================\n",
            "  INDIVIDUAL MODELS: ANEMIA DECISION (BINARY)  \n",
            "==============================\n",
            "\n",
            "--- Training Logistic Regression ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.91      2034\n",
            "           1       0.84      0.90      0.87      1249\n",
            "\n",
            "    accuracy                           0.90      3283\n",
            "   macro avg       0.89      0.90      0.89      3283\n",
            "weighted avg       0.90      0.90      0.90      3283\n",
            "\n",
            "\n",
            "--- Training K-Nearest Neighbors ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      2034\n",
            "           1       0.86      0.89      0.87      1249\n",
            "\n",
            "    accuracy                           0.90      3283\n",
            "   macro avg       0.89      0.90      0.90      3283\n",
            "weighted avg       0.90      0.90      0.90      3283\n",
            "\n",
            "\n",
            "--- Training Gaussian Naive Bayes ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.89      0.91      2034\n",
            "           1       0.83      0.88      0.86      1249\n",
            "\n",
            "    accuracy                           0.89      3283\n",
            "   macro avg       0.88      0.89      0.88      3283\n",
            "weighted avg       0.89      0.89      0.89      3283\n",
            "\n",
            "\n",
            "--- Training Support Vector (RBF) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93      2034\n",
            "           1       0.88      0.90      0.89      1249\n",
            "\n",
            "    accuracy                           0.92      3283\n",
            "   macro avg       0.91      0.91      0.91      3283\n",
            "weighted avg       0.92      0.92      0.92      3283\n",
            "\n",
            "\n",
            "--- Training Decision Tree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93      2034\n",
            "           1       0.89      0.89      0.89      1249\n",
            "\n",
            "    accuracy                           0.92      3283\n",
            "   macro avg       0.91      0.91      0.91      3283\n",
            "weighted avg       0.92      0.92      0.92      3283\n",
            "\n",
            "\n",
            "--- Training Random Forest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.96      2034\n",
            "           1       0.97      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "\n",
            "--- Training Gradient Boosting ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.96      2034\n",
            "           1       0.96      0.89      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "\n",
            "--- Training XGBoost ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [04:16:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      2034\n",
            "           1       0.94      0.89      0.91      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.94      0.93      0.93      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "\n",
            "--- Training LightGBM ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      2034\n",
            "           1       0.96      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "\n",
            "==============================\n",
            "  INDIVIDUAL MODELS: ANEMIA TYPE (MULTICLASS)  \n",
            "==============================\n",
            "\n",
            "--- Training Logistic Regression ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.83      0.20        30\n",
            "           1       0.17      1.00      0.30        26\n",
            "           2       0.27      0.52      0.36       195\n",
            "           3       0.73      0.58      0.65       837\n",
            "           4       0.96      0.83      0.89      2195\n",
            "\n",
            "    accuracy                           0.75      3283\n",
            "   macro avg       0.45      0.75      0.48      3283\n",
            "weighted avg       0.85      0.75      0.78      3283\n",
            "\n",
            "\n",
            "--- Training K-Nearest Neighbors ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      0.37      0.15        30\n",
            "           1       0.18      0.54      0.27        26\n",
            "           2       0.19      0.41      0.26       195\n",
            "           3       0.71      0.63      0.66       837\n",
            "           4       0.96      0.84      0.90      2195\n",
            "\n",
            "    accuracy                           0.75      3283\n",
            "   macro avg       0.43      0.56      0.45      3283\n",
            "weighted avg       0.83      0.75      0.79      3283\n",
            "\n",
            "\n",
            "--- Training Gaussian Naive Bayes ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.77      0.15        30\n",
            "           1       0.17      0.65      0.27        26\n",
            "           2       0.23      0.52      0.32       195\n",
            "           3       0.63      0.58      0.60       837\n",
            "           4       0.97      0.74      0.84      2195\n",
            "\n",
            "    accuracy                           0.69      3283\n",
            "   macro avg       0.41      0.65      0.44      3283\n",
            "weighted avg       0.82      0.69      0.74      3283\n",
            "\n",
            "\n",
            "--- Training Support Vector (RBF) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.70      0.18        30\n",
            "           1       0.19      0.77      0.31        26\n",
            "           2       0.24      0.62      0.35       195\n",
            "           3       0.81      0.56      0.66       837\n",
            "           4       0.97      0.84      0.90      2195\n",
            "\n",
            "    accuracy                           0.75      3283\n",
            "   macro avg       0.46      0.70      0.48      3283\n",
            "weighted avg       0.87      0.75      0.79      3283\n",
            "\n",
            "\n",
            "--- Training Decision Tree ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.43      0.30        30\n",
            "           1       0.29      0.35      0.32        26\n",
            "           2       0.26      0.42      0.32       195\n",
            "           3       0.72      0.68      0.70       837\n",
            "           4       0.94      0.90      0.92      2195\n",
            "\n",
            "    accuracy                           0.81      3283\n",
            "   macro avg       0.49      0.56      0.51      3283\n",
            "weighted avg       0.84      0.81      0.82      3283\n",
            "\n",
            "\n",
            "--- Training Random Forest ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.67      0.37        30\n",
            "           1       0.31      0.65      0.42        26\n",
            "           2       0.35      0.43      0.39       195\n",
            "           3       0.83      0.72      0.77       837\n",
            "           4       0.95      0.94      0.94      2195\n",
            "\n",
            "    accuracy                           0.85      3283\n",
            "   macro avg       0.54      0.68      0.58      3283\n",
            "weighted avg       0.87      0.85      0.86      3283\n",
            "\n",
            "\n",
            "--- Training Gradient Boosting ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.87      0.27        30\n",
            "           1       0.27      0.88      0.41        26\n",
            "           2       0.27      0.58      0.37       195\n",
            "           3       0.86      0.59      0.70       837\n",
            "           4       0.96      0.89      0.92      2195\n",
            "\n",
            "    accuracy                           0.79      3283\n",
            "   macro avg       0.50      0.76      0.54      3283\n",
            "weighted avg       0.88      0.79      0.82      3283\n",
            "\n",
            "\n",
            "--- Training XGBoost ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [04:18:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.60      0.34        30\n",
            "           1       0.35      0.73      0.47        26\n",
            "           2       0.30      0.45      0.36       195\n",
            "           3       0.82      0.69      0.75       837\n",
            "           4       0.95      0.93      0.94      2195\n",
            "\n",
            "    accuracy                           0.84      3283\n",
            "   macro avg       0.53      0.68      0.57      3283\n",
            "weighted avg       0.87      0.84      0.85      3283\n",
            "\n",
            "\n",
            "--- Training LightGBM ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.60      0.30        30\n",
            "           1       0.35      0.69      0.47        26\n",
            "           2       0.31      0.49      0.38       195\n",
            "           3       0.83      0.68      0.75       837\n",
            "           4       0.95      0.93      0.94      2195\n",
            "\n",
            "    accuracy                           0.84      3283\n",
            "   macro avg       0.53      0.68      0.57      3283\n",
            "weighted avg       0.87      0.84      0.85      3283\n",
            "\n",
            "\n",
            "==============================\n",
            "  VOTING ENSEMBLE: ANEMIA DECISION (BINARY)  \n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      2034\n",
            "           1       0.95      0.89      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.94      0.93      0.93      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "\n",
            "==============================\n",
            "  VOTING ENSEMBLE: ANEMIA TYPE (MULTICLASS)  \n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.77      0.28        30\n",
            "           1       0.28      0.85      0.42        26\n",
            "           2       0.30      0.57      0.40       195\n",
            "           3       0.85      0.64      0.73       837\n",
            "           4       0.96      0.90      0.93      2195\n",
            "\n",
            "    accuracy                           0.81      3283\n",
            "   macro avg       0.51      0.75      0.55      3283\n",
            "weighted avg       0.88      0.81      0.84      3283\n",
            "\n",
            "\n",
            "==============================\n",
            "  STACKING ENSEMBLE: ANEMIA DECISION (BINARY)  \n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      2034\n",
            "           1       0.95      0.89      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.94      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "\n",
            "==============================\n",
            "  STACKING ENSEMBLE: ANEMIA TYPE (MULTICLASS)  \n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.30      0.29        30\n",
            "           1       0.38      0.38      0.38        26\n",
            "           2       0.32      0.26      0.29       195\n",
            "           3       0.79      0.79      0.79       837\n",
            "           4       0.94      0.95      0.95      2195\n",
            "\n",
            "    accuracy                           0.86      3283\n",
            "   macro avg       0.54      0.54      0.54      3283\n",
            "weighted avg       0.85      0.86      0.86      3283\n",
            "\n",
            "\n",
            "=== Model Training Complete ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost lightgbm catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R3iZ83ZIIJQ",
        "outputId": "1e7f6ba7-74c9-490a-a318-baa9a4e52bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# SECTION 1: IMPORTS\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from collections import Counter\n",
        "\n",
        "# --- Preprocessing & Metrics ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import RFE # <-- For Feature Selection\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# --- Imbalanced-Learn ---\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek # <-- Advanced Balancing\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# --- Base Models ---\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# --- Ensemble Models ---\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    StackingClassifier\n",
        ")\n",
        "\n",
        "# --- Boosting Libraries (Import with aliases) ---\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    import lightgbm as lgb\n",
        "    import catboost as cb\n",
        "    HAVE_BOOSTING = True\n",
        "except ImportError:\n",
        "    HAVE_BOOSTING = False\n",
        "    print(\"Warning: XGBoost, LightGBM, or CatBoost not installed. Skipping some models.\")\n",
        "    print(\"To install: pip install xgboost lightgbm catboost\")\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 2: HELPER FUNCTIONS\n",
        "# -----------------------------\n",
        "\n",
        "def get_model_list():\n",
        "    \"\"\"Returns your custom list of (name, model) tuples.\"\"\"\n",
        "    model_list = [\n",
        "        ('knn', KNeighborsClassifier(n_neighbors=7)),\n",
        "        ('svm', SVC(probability=True, kernel='rbf', random_state=42)),\n",
        "        ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "        ('rf', RandomForestClassifier(n_estimators=150, random_state=42)),\n",
        "        ('gb', GradientBoostingClassifier(random_state=42)),\n",
        "        ('mlp', MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42))\n",
        "    ]\n",
        "\n",
        "    if HAVE_BOOSTING:\n",
        "        model_list.extend([\n",
        "            ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
        "            ('lgb', lgb.LGBMClassifier(random_state=42, verbose=-1)),\n",
        "            ('cat', cb.CatBoostClassifier(verbose=0, random_state=42))\n",
        "        ])\n",
        "    else:\n",
        "        print(\"---! Boosted models (XGB, LGB, Cat) not found !---\")\n",
        "\n",
        "    return model_list\n",
        "\n",
        "def print_all_metrics(y_true, y_pred, model_name, average_type):\n",
        "    \"\"\"Prints a formatted block of classification metrics.\"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    pre = precision_score(y_true, y_pred, average=average_type, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, average=average_type, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average=average_type, zero_division=0)\n",
        "\n",
        "    print(f\"{model_name} Metrics ({average_type} average):\")\n",
        "    print(f\"  Accuracy:  {acc:.4f}\")\n",
        "    print(f\"  Precision: {pre:.4f}\")\n",
        "    print(f\"  Recall:    {rec:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1:.4f}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 3: LOAD DATA\n",
        "# -----------------------------\n",
        "try:\n",
        "    df = pd.read_csv('/content/anemia_final_dataset_ready_for_ml.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset file not found.\")\n",
        "    print(\"Please ensure '/content/anemia_final_dataset_ready_for_ml.csv' is uploaded.\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 4: ADVANCED FEATURE ENGINEERING\n",
        "# -----------------------------\n",
        "print(\"\\n--- Starting Feature Engineering ---\")\n",
        "# Use .replace(0, 1e-6) to avoid division by zero\n",
        "df['hgb_to_rbc_ratio'] = df['hgb'] / (df['rbc'].replace(0, 1e-6))\n",
        "df['mcv_mch_ratio'] = df['mcv'] / (df['mch'].replace(0, 1e-6))\n",
        "df['b12_folate_ratio'] = df['b12'] / (df['folate'].replace(0, 1e-6))\n",
        "df['ferritin_to_hgb'] = df['ferritin'] / (df['hgb'].replace(0, 1e-6))\n",
        "\n",
        "# Define the new, complete feature list\n",
        "original_features = ['rbc', 'hgb', 'mcv', 'mch', 'mchc', 'b12', 'folate', 'ferritin']\n",
        "ratio_features = ['hgb_to_rbc_ratio', 'mcv_mch_ratio', 'b12_folate_ratio', 'ferritin_to_hgb']\n",
        "features_all = original_features + ratio_features\n",
        "\n",
        "print(f\"Created {len(ratio_features)} new features. Total features: {len(features_all)}\")\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 5: DEFINE X AND Y\n",
        "# -----------------------------\n",
        "X = df[features_all]\n",
        "y_dec = df['decision']\n",
        "y_type = df['anemia_type_encoded']\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 6: TRAIN/TEST SPLIT\n",
        "# -----------------------------\n",
        "# This is the most important step for preventing data leakage.\n",
        "X_train, X_test, y_train_dec, y_test_dec = train_test_split(\n",
        "    X, y_dec, test_size=0.2, random_state=42, stratify=y_dec\n",
        ")\n",
        "\n",
        "y_train_type = y_type.loc[X_train.index]\n",
        "y_test_type = y_type.loc[X_test.index]\n",
        "\n",
        "print(f\"\\nOriginal X_train shape: {X_train.shape}\")\n",
        "print(f\"Original X_test shape: {X_test.shape}\")\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 7: FEATURE SELECTION (RFE)\n",
        "# -----------------------------\n",
        "print(\"\\n--- Running RFE to select top features ---\")\n",
        "# RFE will find the best 8 features from our total list of 12\n",
        "rfe = RFE(\n",
        "    estimator=RandomForestClassifier(n_estimators=50, random_state=42),\n",
        "    n_features_to_select=8, # We'll select the best 8\n",
        "    step=1\n",
        ")\n",
        "\n",
        "# Fit RFE *only* on the training data\n",
        "rfe.fit(X_train, y_train_dec)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_features_mask = rfe.support_\n",
        "selected_feature_names = X_train.columns[selected_features_mask]\n",
        "print(f\"Top 8 selected features: {list(selected_feature_names)}\")\n",
        "\n",
        "# Transform our train and test sets to use *only* these features\n",
        "X_train_rfe = rfe.transform(X_train)\n",
        "X_test_rfe = rfe.transform(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 8: FEATURE SCALING\n",
        "# -----------------------------\n",
        "print(\"\\n--- Scaling selected features ---\")\n",
        "scaler = StandardScaler()\n",
        "# Fit the scaler *only* on the RFE-transformed training data\n",
        "X_train_scaled = scaler.fit_transform(X_train_rfe)\n",
        "# Transform the test data\n",
        "X_test_scaled = scaler.transform(X_test_rfe)\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 9: ADVANCED BALANCING\n",
        "# -----------------------------\n",
        "# We'll use SMOTE-Tomek, which oversamples and then cleans noisy data\n",
        "balancing_pipeline_smote_tomek = SMOTETomek(\n",
        "    random_state=42,\n",
        "    smote=SMOTE(random_state=42, k_neighbors=3), # k=3 for small classes\n",
        "    tomek=None # Use default TomekLinks\n",
        ")\n",
        "\n",
        "# --- Balancing for Binary (Decision) Task ---\n",
        "print(\"\\nBalancing binary 'decision' target with SMOTE-Tomek...\")\n",
        "X_train_dec_bal, y_train_dec_bal = balancing_pipeline_smote_tomek.fit_resample(\n",
        "    X_train_scaled, y_train_dec\n",
        ")\n",
        "print(f\"Decision - Original: {Counter(y_train_dec)} | Balanced: {Counter(y_train_dec_bal)}\")\n",
        "\n",
        "# --- Balancing for Multiclass (Type) Task ---\n",
        "print(\"Balancing multiclass 'type' target with SMOTE-Tomek...\")\n",
        "X_train_type_bal, y_train_type_bal = balancing_pipeline_smote_tomek.fit_resample(\n",
        "    X_train_scaled, y_train_type\n",
        ")\n",
        "print(f\"Type - Original: {Counter(y_train_type)} | Balanced: {Counter(y_train_type_bal)}\")\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 10: INDIVIDUAL MODELS (LOOP)\n",
        "# -----------------------------\n",
        "models_to_test = dict(get_model_list())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  INDIVIDUAL MODELS: ANEMIA DECISION (BINARY)  \")\n",
        "print(\"=\" * 30)\n",
        "for name, model in models_to_test.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "    model.fit(X_train_dec_bal, y_train_dec_bal)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    print(classification_report(y_test_dec, y_pred, zero_division=0))\n",
        "    print_all_metrics(y_test_dec, y_pred, name, average_type='weighted')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  INDIVIDUAL MODELS: ANEMIA TYPE (MULTICLASS)  \")\n",
        "print(\"=\" * 30)\n",
        "for name, model in models_to_test.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "    model.fit(X_train_type_bal, y_train_type_bal)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    print(classification_report(y_test_type, y_pred, zero_division=0))\n",
        "    print_all_metrics(y_test_type, y_pred, name, average_type='weighted')\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# SECTION 11: STACKING ENSEMBLE (FINAL MODEL)\n",
        "# -----------------------------\n",
        "# Get a fresh list of model objects for the stack\n",
        "base_learners = get_model_list()\n",
        "\n",
        "# --- Stacking: Anemia Decision (Binary) ---\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  STACKING ENSEMBLE: ANEMIA DECISION (BINARY)  \")\n",
        "print(\"=\" * 30)\n",
        "stack_clf_dec = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "stack_clf_dec.fit(X_train_dec_bal, y_train_dec_bal)\n",
        "y_pred_dec = stack_clf_dec.predict(X_test_scaled)\n",
        "\n",
        "print(classification_report(y_test_dec, y_pred_dec, zero_division=0))\n",
        "print_all_metrics(y_test_dec, y_pred_dec, \"Stacking Ensemble\", average_type='weighted')\n",
        "\n",
        "# --- Stacking: Anemia Type (Multiclass) ---\n",
        "print(\"\\n\" + \"=\" * 30)\n",
        "print(\"  STACKING ENSEMBLE: ANEMIA TYPE (MULTICLASS)  \")\n",
        "print(\"=\" * 30)\n",
        "stack_clf_type = StackingClassifier(\n",
        "    estimators=base_learners,\n",
        "    final_estimator=LogisticRegression(max_iter=1000),\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "stack_clf_type.fit(X_train_type_bal, y_train_type_bal)\n",
        "y_pred_type = stack_clf_type.predict(X_test_scaled)\n",
        "\n",
        "print(classification_report(y_test_type, y_pred_type, zero_division=0))\n",
        "print_all_metrics(y_test_type, y_pred_type, \"Stacking Ensemble\", average_type='weighted')\n",
        "\n",
        "print(\"\\n=== All Model Training and Evaluation Complete ===\")"
      ],
      "metadata": {
        "id": "mbmgqP0cNbje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397ae798-84bd-4ce4-87f2-40156defbff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Feature Engineering ---\n",
            "Created 4 new features. Total features: 12\n",
            "\n",
            "Original X_train shape: (13131, 12)\n",
            "Original X_test shape: (3283, 12)\n",
            "\n",
            "--- Running RFE to select top features ---\n",
            "Top 8 selected features: ['rbc', 'hgb', 'mcv', 'mch', 'b12', 'hgb_to_rbc_ratio', 'mcv_mch_ratio', 'ferritin_to_hgb']\n",
            "\n",
            "--- Scaling selected features ---\n",
            "\n",
            "Balancing binary 'decision' target with SMOTE-Tomek...\n",
            "Decision - Original: Counter({0: 8136, 1: 4995}) | Balanced: Counter({0: 7955, 1: 7955})\n",
            "Balancing multiclass 'type' target with SMOTE-Tomek...\n",
            "Type - Original: Counter({4: 8650, 3: 3358, 2: 824, 0: 172, 1: 127}) | Balanced: Counter({0: 8650, 1: 8648, 2: 8601, 4: 8561, 3: 8560})\n",
            "\n",
            "==============================\n",
            "  INDIVIDUAL MODELS: ANEMIA DECISION (BINARY)  \n",
            "==============================\n",
            "\n",
            "--- Training knn ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93      2034\n",
            "           1       0.88      0.90      0.89      1249\n",
            "\n",
            "    accuracy                           0.91      3283\n",
            "   macro avg       0.91      0.91      0.91      3283\n",
            "weighted avg       0.91      0.91      0.91      3283\n",
            "\n",
            "knn Metrics (weighted average):\n",
            "  Accuracy:  0.9141\n",
            "  Precision: 0.9148\n",
            "  Recall:    0.9141\n",
            "  F1-Score:  0.9143\n",
            "--------------------\n",
            "\n",
            "--- Training svm ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93      2034\n",
            "           1       0.89      0.90      0.89      1249\n",
            "\n",
            "    accuracy                           0.92      3283\n",
            "   macro avg       0.91      0.92      0.91      3283\n",
            "weighted avg       0.92      0.92      0.92      3283\n",
            "\n",
            "svm Metrics (weighted average):\n",
            "  Accuracy:  0.9187\n",
            "  Precision: 0.9190\n",
            "  Recall:    0.9187\n",
            "  F1-Score:  0.9188\n",
            "--------------------\n",
            "\n",
            "--- Training dt ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      2034\n",
            "           1       0.90      0.90      0.90      1249\n",
            "\n",
            "    accuracy                           0.92      3283\n",
            "   macro avg       0.92      0.92      0.92      3283\n",
            "weighted avg       0.92      0.92      0.92      3283\n",
            "\n",
            "dt Metrics (weighted average):\n",
            "  Accuracy:  0.9217\n",
            "  Precision: 0.9217\n",
            "  Recall:    0.9217\n",
            "  F1-Score:  0.9217\n",
            "--------------------\n",
            "\n",
            "--- Training rf ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      2034\n",
            "           1       0.97      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "rf Metrics (weighted average):\n",
            "  Accuracy:  0.9424\n",
            "  Precision: 0.9438\n",
            "  Recall:    0.9424\n",
            "  F1-Score:  0.9418\n",
            "--------------------\n",
            "\n",
            "--- Training gb ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      2034\n",
            "           1       0.96      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.94      0.93      0.93      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "gb Metrics (weighted average):\n",
            "  Accuracy:  0.9397\n",
            "  Precision: 0.9405\n",
            "  Recall:    0.9397\n",
            "  F1-Score:  0.9392\n",
            "--------------------\n",
            "\n",
            "--- Training mlp ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.96      2034\n",
            "           1       0.96      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "mlp Metrics (weighted average):\n",
            "  Accuracy:  0.9430\n",
            "  Precision: 0.9440\n",
            "  Recall:    0.9430\n",
            "  F1-Score:  0.9425\n",
            "--------------------\n",
            "\n",
            "--- Training xgb ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      2034\n",
            "           1       0.95      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.94      0.93      0.93      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "xgb Metrics (weighted average):\n",
            "  Accuracy:  0.9382\n",
            "  Precision: 0.9387\n",
            "  Recall:    0.9382\n",
            "  F1-Score:  0.9377\n",
            "--------------------\n",
            "\n",
            "--- Training lgb ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96      2034\n",
            "           1       0.96      0.89      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.95      0.94      0.94      3283\n",
            "\n",
            "lgb Metrics (weighted average):\n",
            "  Accuracy:  0.9446\n",
            "  Precision: 0.9453\n",
            "  Recall:    0.9446\n",
            "  F1-Score:  0.9441\n",
            "--------------------\n",
            "\n",
            "--- Training cat ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.96      2034\n",
            "           1       0.96      0.89      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.95      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "cat Metrics (weighted average):\n",
            "  Accuracy:  0.9436\n",
            "  Precision: 0.9445\n",
            "  Recall:    0.9436\n",
            "  F1-Score:  0.9432\n",
            "--------------------\n",
            "\n",
            "==============================\n",
            "  INDIVIDUAL MODELS: ANEMIA TYPE (MULTICLASS)  \n",
            "==============================\n",
            "\n",
            "--- Training knn ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      0.40      0.14        30\n",
            "           1       0.03      0.19      0.05        26\n",
            "           2       0.19      0.43      0.26       195\n",
            "           3       0.75      0.60      0.66       837\n",
            "           4       0.97      0.83      0.89      2195\n",
            "\n",
            "    accuracy                           0.74      3283\n",
            "   macro avg       0.40      0.49      0.40      3283\n",
            "weighted avg       0.85      0.74      0.78      3283\n",
            "\n",
            "knn Metrics (weighted average):\n",
            "  Accuracy:  0.7365\n",
            "  Precision: 0.8490\n",
            "  Recall:    0.7365\n",
            "  F1-Score:  0.7830\n",
            "--------------------\n",
            "\n",
            "--- Training svm ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.73      0.17        30\n",
            "           1       0.03      0.19      0.05        26\n",
            "           2       0.24      0.53      0.33       195\n",
            "           3       0.82      0.57      0.67       837\n",
            "           4       0.97      0.83      0.89      2195\n",
            "\n",
            "    accuracy                           0.74      3283\n",
            "   macro avg       0.43      0.57      0.42      3283\n",
            "weighted avg       0.87      0.74      0.79      3283\n",
            "\n",
            "svm Metrics (weighted average):\n",
            "  Accuracy:  0.7359\n",
            "  Precision: 0.8727\n",
            "  Recall:    0.7359\n",
            "  F1-Score:  0.7885\n",
            "--------------------\n",
            "\n",
            "--- Training dt ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.33      0.22        30\n",
            "           1       0.04      0.15      0.06        26\n",
            "           2       0.22      0.35      0.27       195\n",
            "           3       0.74      0.65      0.69       837\n",
            "           4       0.95      0.89      0.92      2195\n",
            "\n",
            "    accuracy                           0.79      3283\n",
            "   macro avg       0.42      0.48      0.43      3283\n",
            "weighted avg       0.84      0.79      0.81      3283\n",
            "\n",
            "dt Metrics (weighted average):\n",
            "  Accuracy:  0.7883\n",
            "  Precision: 0.8371\n",
            "  Recall:    0.7883\n",
            "  F1-Score:  0.8100\n",
            "--------------------\n",
            "\n",
            "--- Training rf ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.40      0.24        30\n",
            "           1       0.00      0.00      0.00        26\n",
            "           2       0.30      0.40      0.35       195\n",
            "           3       0.83      0.71      0.77       837\n",
            "           4       0.95      0.94      0.94      2195\n",
            "\n",
            "    accuracy                           0.83      3283\n",
            "   macro avg       0.45      0.49      0.46      3283\n",
            "weighted avg       0.87      0.83      0.85      3283\n",
            "\n",
            "rf Metrics (weighted average):\n",
            "  Accuracy:  0.8337\n",
            "  Precision: 0.8669\n",
            "  Recall:    0.8337\n",
            "  F1-Score:  0.8482\n",
            "--------------------\n",
            "\n",
            "--- Training gb ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.90      0.26        30\n",
            "           1       0.02      0.12      0.04        26\n",
            "           2       0.23      0.53      0.32       195\n",
            "           3       0.88      0.57      0.69       837\n",
            "           4       0.97      0.87      0.92      2195\n",
            "\n",
            "    accuracy                           0.77      3283\n",
            "   macro avg       0.45      0.60      0.44      3283\n",
            "weighted avg       0.89      0.77      0.81      3283\n",
            "\n",
            "gb Metrics (weighted average):\n",
            "  Accuracy:  0.7676\n",
            "  Precision: 0.8857\n",
            "  Recall:    0.7676\n",
            "  F1-Score:  0.8102\n",
            "--------------------\n",
            "\n",
            "--- Training mlp ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.60      0.28        30\n",
            "           1       0.02      0.08      0.03        26\n",
            "           2       0.20      0.53      0.29       195\n",
            "           3       0.80      0.58      0.67       837\n",
            "           4       0.97      0.86      0.91      2195\n",
            "\n",
            "    accuracy                           0.76      3283\n",
            "   macro avg       0.43      0.53      0.44      3283\n",
            "weighted avg       0.86      0.76      0.80      3283\n",
            "\n",
            "mlp Metrics (weighted average):\n",
            "  Accuracy:  0.7594\n",
            "  Precision: 0.8625\n",
            "  Recall:    0.7594\n",
            "  F1-Score:  0.7990\n",
            "--------------------\n",
            "\n",
            "--- Training xgb ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.53      0.27        30\n",
            "           1       0.00      0.00      0.00        26\n",
            "           2       0.27      0.42      0.32       195\n",
            "           3       0.84      0.65      0.73       837\n",
            "           4       0.96      0.93      0.94      2195\n",
            "\n",
            "    accuracy                           0.82      3283\n",
            "   macro avg       0.45      0.51      0.45      3283\n",
            "weighted avg       0.87      0.82      0.84      3283\n",
            "\n",
            "xgb Metrics (weighted average):\n",
            "  Accuracy:  0.8182\n",
            "  Precision: 0.8700\n",
            "  Recall:    0.8182\n",
            "  F1-Score:  0.8393\n",
            "--------------------\n",
            "\n",
            "--- Training lgb ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.57      0.27        30\n",
            "           1       0.00      0.00      0.00        26\n",
            "           2       0.26      0.44      0.33       195\n",
            "           3       0.85      0.66      0.74       837\n",
            "           4       0.96      0.92      0.94      2195\n",
            "\n",
            "    accuracy                           0.81      3283\n",
            "   macro avg       0.45      0.52      0.46      3283\n",
            "weighted avg       0.87      0.81      0.84      3283\n",
            "\n",
            "lgb Metrics (weighted average):\n",
            "  Accuracy:  0.8115\n",
            "  Precision: 0.8725\n",
            "  Recall:    0.8115\n",
            "  F1-Score:  0.8365\n",
            "--------------------\n",
            "\n",
            "--- Training cat ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.57      0.25        30\n",
            "           1       0.01      0.04      0.01        26\n",
            "           2       0.28      0.42      0.34       195\n",
            "           3       0.84      0.66      0.73       837\n",
            "           4       0.95      0.92      0.94      2195\n",
            "\n",
            "    accuracy                           0.81      3283\n",
            "   macro avg       0.45      0.52      0.45      3283\n",
            "weighted avg       0.87      0.81      0.84      3283\n",
            "\n",
            "cat Metrics (weighted average):\n",
            "  Accuracy:  0.8130\n",
            "  Precision: 0.8681\n",
            "  Recall:    0.8130\n",
            "  F1-Score:  0.8357\n",
            "--------------------\n",
            "\n",
            "==============================\n",
            "  STACKING ENSEMBLE: ANEMIA DECISION (BINARY)  \n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      2034\n",
            "           1       0.95      0.88      0.92      1249\n",
            "\n",
            "    accuracy                           0.94      3283\n",
            "   macro avg       0.94      0.93      0.94      3283\n",
            "weighted avg       0.94      0.94      0.94      3283\n",
            "\n",
            "Stacking Ensemble Metrics (weighted average):\n",
            "  Accuracy:  0.9400\n",
            "  Precision: 0.9406\n",
            "  Recall:    0.9400\n",
            "  F1-Score:  0.9395\n",
            "--------------------\n",
            "\n",
            "==============================\n",
            "  STACKING ENSEMBLE: ANEMIA TYPE (MULTICLASS)  \n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.27      0.24        30\n",
            "           1       0.00      0.00      0.00        26\n",
            "           2       0.27      0.30      0.29       195\n",
            "           3       0.80      0.74      0.77       837\n",
            "           4       0.95      0.95      0.95      2195\n",
            "\n",
            "    accuracy                           0.84      3283\n",
            "   macro avg       0.45      0.45      0.45      3283\n",
            "weighted avg       0.85      0.84      0.85      3283\n",
            "\n",
            "Stacking Ensemble Metrics (weighted average):\n",
            "  Accuracy:  0.8422\n",
            "  Precision: 0.8533\n",
            "  Recall:    0.8422\n",
            "  F1-Score:  0.8474\n",
            "--------------------\n",
            "\n",
            "=== All Model Training and Evaluation Complete ===\n"
          ]
        }
      ]
    }
  ]
}